{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtI9sIt2HMILhENeqLWna3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boiBASH/Elite-Bank-Project/blob/main/Data_Transformation_and_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hzdsl2KG0EOu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install mlflow\n",
        "!pip install pyngrok\n",
        "!pip install catboost\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
      ],
      "metadata": {
        "id": "8YJMCUvb0fbX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
        "subprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", MLFLOW_TRACKING_URI])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZx8HvOV09vF",
        "outputId": "2fb77ff7-4c0f-4d60-aff6-6d2d5ea8a3c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['mlflow', 'ui', '--backend-store-uri', 'sqli...>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "# mlflow will create an experiment if it doesn't exist\n",
        "mlflow.set_experiment(\"EliteBank ML\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zzuri2p1BjZ",
        "outputId": "aa75e9b3-2121-43bc-95de-4c7431002149"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/03/10 02:14:40 INFO mlflow.tracking.fluent: Experiment with name 'EliteBank ML' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/1', creation_time=1741572880711, experiment_id='1', last_update_time=1741572880711, lifecycle_stage='active', name='EliteBank ML', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "port=5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f' * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QonbzJM1UnL",
        "outputId": "a0400d24-ee01-4667-d7cb-b92bae4dc428"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\n",
            "··········\n",
            " * ngrok tunnel \"https://aced-35-221-183-84.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Bank_Marketing_Dataset.csv\")"
      ],
      "metadata": {
        "id": "l-r2YylV0xbH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the column types\n",
        "scale_columns = [\n",
        "    \"age\",\n",
        "    \"balance\",\n",
        "    \"day\",\n",
        "    \"duration\"\n",
        "]\n",
        "\n",
        "categorical_columns = df.select_dtypes(include = [\"object\"]).columns.tolist()\n",
        "categorical_columns.remove(\"deposit\")"
      ],
      "metadata": {
        "id": "otrfETck1i35"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and labels from dataset\n",
        "X, y = df.drop(labels = [\"deposit\"], axis = 1), df[\"deposit\"]"
      ],
      "metadata": {
        "id": "weRAi3ts1tP2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "map_dictionary = {\n",
        "    \"yes\": 1,\n",
        "    \"no\": 0\n",
        "}\n",
        "\n",
        "y = y.apply(lambda x: map_dictionary[x])"
      ],
      "metadata": {
        "id": "5i5iq45E10k0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate into train and test splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, stratify = y)"
      ],
      "metadata": {
        "id": "_tI19pLJ13NL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement data preparation transformer\n",
        "def get_transformer(categorical_columns, scale_columns, one_hot=False):\n",
        "    if one_hot:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[\n",
        "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
        "                (\"scale\", StandardScaler(), scale_columns)\n",
        "            ],\n",
        "            remainder=\"passthrough\"\n",
        "        )\n",
        "    else:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[\n",
        "                (\"ordinal\", OrdinalEncoder(), categorical_columns),\n",
        "                (\"scale\", StandardScaler(), scale_columns)\n",
        "            ],\n",
        "            remainder=\"passthrough\"\n",
        "        )\n",
        "    return transformer"
      ],
      "metadata": {
        "id": "LZZa9WDp2Dok"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model pipelines\n",
        "log_pipe = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", get_transformer(categorical_columns, scale_columns, one_hot=True)),\n",
        "        (\"model\", LogisticRegression(max_iter=1000))\n",
        "    ]\n",
        ")\n",
        "\n",
        "cat_pipe = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", get_transformer(categorical_columns, scale_columns, one_hot=False)),\n",
        "        (\"model\", CatBoostClassifier(verbose=0, random_seed=42))\n",
        "    ]\n",
        ")\n",
        "\n",
        "extra_pipe = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", get_transformer(categorical_columns, scale_columns, one_hot=False)),\n",
        "        (\"model\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42))\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "7ZQGTRW12yYW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train, evaluate, and log models in MLflow\n",
        "def train_and_log_pipeline(pipeline, model_name):\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "\n",
        "        # Train model\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Compute evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "        # Compute specificity\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else None\n",
        "\n",
        "        # Log metrics in MLflow\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_metric(\"precision\", precision)\n",
        "        mlflow.log_metric(\"recall\", recall)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n",
        "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "        if specificity is not None:\n",
        "            mlflow.log_metric(\"specificity\", specificity)\n",
        "\n",
        "        # Log model\n",
        "        mlflow.sklearn.log_model(pipeline, model_name)\n",
        "\n",
        "        print(f\"✅ Model {model_name} logged successfully in MLflow!\")\n",
        "\n",
        "# Set up MLflow experiment\n",
        "mlflow.set_experiment(\"Long-Term Investor Prediction\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNR4IKeO2yh-",
        "outputId": "f24b7af7-7fac-4c3a-d910-68a23b3c99f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/03/10 02:22:39 INFO mlflow.tracking.fluent: Experiment with name 'Long-Term Investor Prediction' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/2', creation_time=1741573359862, experiment_id='2', last_update_time=1741573359862, lifecycle_stage='active', name='Long-Term Investor Prediction', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and log all models\n",
        "train_and_log_pipeline(log_pipe, \"Logistic Regression\")\n",
        "train_and_log_pipeline(cat_pipe, \"CatBoost\")\n",
        "train_and_log_pipeline(extra_pipe, \"XGBoost\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQBu2o83J54",
        "outputId": "0c610402-c1d3-4aff-9e2c-2b481161d7d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/10 02:23:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model Logistic Regression logged successfully in MLflow!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/10 02:23:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:23:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model CatBoost logged successfully in MLflow!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/03/10 02:23:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model XGBoost logged successfully in MLflow!\n"
          ]
        }
      ]
    }
  ]
}